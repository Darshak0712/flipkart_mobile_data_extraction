{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup \n",
    "import requests\n",
    "import openpyxl\n",
    "from openpyxl.workbook import Workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.flipkart.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_data = [] \n",
    "column_titles = [ \"Name\" ,\"Selling_price\" ,\"Colour\" , \"ROM\" , \"Memory\" , \"Display\" , \"Camera\" , \"Battery\" , \"Processor\" ,\"Others\" , \"Product_ratings\" ,\"Camera_ratings\" , \"Battery_ratings\" , \"Display_ratings\" , \"Value for Money\" ,\"Seller_Name\" , \"Seller_Ratings\" , \"Product_Link\" ]\n",
    "final_data = []\n",
    "is_first_call = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_categories_from_topbar(url):\n",
    "    \"\"\"Provides categories & required details from home page top bar\"\"\"\n",
    "    global temp_data\n",
    "    # Request to url page for data \n",
    "    page = requests.get(url)\n",
    "    htmCont = page.content\n",
    "    \n",
    "    # Html Content Parsing\n",
    "    soup =  BeautifulSoup(htmCont,'html.parser') \n",
    "    \n",
    "    #Fetch category titles\n",
    "    top_category_bar = soup.find_all('div',class_=\"eFQ30H\")\n",
    "    \n",
    "    # Target Category detail to get return\n",
    "    Mobile_category_link = \"\"\n",
    "    \n",
    "    print(\"List of categories at top-bar home page\\n\")\n",
    "    \n",
    "    #Iterating over categories , can get Titles with respective link\n",
    "    for i in range(len(top_category_bar)):\n",
    "        category_name = top_category_bar[i].text\n",
    "        try:\n",
    "            category_link = top_category_bar[i].find('a')['href']\n",
    "        except:\n",
    "            category_link = \"\"\n",
    "        \n",
    "        # To get mobile category link to extract further details\n",
    "        if category_name == \"Mobiles\":\n",
    "            Mobile_category_link = category_link\n",
    "        \n",
    "        print(f\"{category_name}\")\n",
    "        print(\"----------------------------------\")\n",
    "        \n",
    "    return Mobile_category_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of categories at top-bar home page\n",
      "\n",
      "Mobiles\n",
      "----------------------------------\n",
      "Fashion\n",
      "----------------------------------\n",
      "Electronics\n",
      "----------------------------------\n",
      "Home\n",
      "----------------------------------\n",
      "Travel\n",
      "----------------------------------\n",
      "Appliances\n",
      "----------------------------------\n",
      "Furniture\n",
      "----------------------------------\n",
      "Beauty,Toys & more\n",
      "----------------------------------\n",
      "Grocery\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "mobile_category_page_link = get_categories_from_topbar(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_to_excel(final_data):\n",
    "    \"\"\"Upload data to excel file\"\"\"\n",
    "    global column_titles\n",
    "    global is_first_call\n",
    "\n",
    "    workbook_name = 'output_flipkart_data.xlsx'\n",
    "    wb = openpyxl.load_workbook(workbook_name)\n",
    "    if is_first_call:\n",
    "        # Write to default sheet during first call\n",
    "        page = wb.active\n",
    "        is_first_call = False\n",
    "    else:\n",
    "        # Creates new sheet for next mobiles list\n",
    "        page = wb.create_sheet()\n",
    "    \n",
    "    # write the headers to the first line\n",
    "    page.append(column_titles) \n",
    "\n",
    "    # Data to write:\n",
    "    for info in final_data:\n",
    "        page.append(info)\n",
    "    wb.save(workbook_name)\n",
    "    wb.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_list_contents(content_list):\n",
    "    \"\"\"Extract data from highlighted to front list\"\"\"\n",
    "    \n",
    "    global temp_data\n",
    "    \n",
    "    memory = \"\"\n",
    "    display = \"\"\n",
    "    camera = \"\"\n",
    "    battery = \"\"\n",
    "    processor = \"\"\n",
    "    other = \"\"\n",
    "    \n",
    "    for data in content_list:\n",
    "        if 'RAM' in data.text:\n",
    "            memory = data.text\n",
    "        elif 'Display' in data.text:\n",
    "            display = data.text\n",
    "        elif 'Camera'.lower() in data.text.lower():\n",
    "            camera = data.text\n",
    "        elif 'Battery' in data.text:\n",
    "            battery = data.text\n",
    "        elif 'Processor' in data.text:\n",
    "            processor = data.text\n",
    "        else:\n",
    "            other += \" \"+ data.text+ \" \"\n",
    "        \n",
    "    temp_data.append(memory)\n",
    "    temp_data.append(display)\n",
    "    temp_data.append(camera)\n",
    "    temp_data.append(battery)\n",
    "    temp_data.append(processor)\n",
    "    temp_data.append(other.strip())\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seller_info(link):\n",
    "    \"\"\"Extraction for seller information & ratings\"\"\"\n",
    "    global temp_data\n",
    "    \n",
    "    page = requests.get(link)\n",
    "    htmCont = page.content\n",
    "\n",
    "    soup =  BeautifulSoup(htmCont,'html.parser')\n",
    "    try:\n",
    "        seller_detail = soup.find('div',{\"id\":\"sellerName\"})\n",
    "\n",
    "        seller = seller_detail.find('span')\n",
    "\n",
    "        seller_name = seller.find('span').text\n",
    "\n",
    "        seller_ratings = seller.find('div',class_=\"_3LWZlK _1D-8OL\").text\n",
    "    except:\n",
    "        seller_name = \"NA\"\n",
    "        seller_ratings = \"NA\"\n",
    "        \n",
    "    ratings_container = soup.find_all('div',class_=\"_2a78PX\")\n",
    "    \n",
    "    camera_rating = \"\"\n",
    "    battery_rating = \"\"\n",
    "    display_rating = \"\"\n",
    "    value_for_money = \"\"\n",
    "    \n",
    "    for rating in ratings_container:\n",
    "    \n",
    "        rate = rating.find('div',class_='_2aWUii').text\n",
    "        tag = rating.find('div',class_='_3npa3F').text\n",
    "        if 'Camera' in tag:\n",
    "            camera_rating = rate\n",
    "        if 'Battery' in tag:\n",
    "            battery_rating = rate\n",
    "        if 'Display' in tag:\n",
    "            display_rating = rate\n",
    "        if 'Money' in tag:\n",
    "            value_for_money = rate\n",
    "    \n",
    "    temp_data.append(camera_rating)\n",
    "    temp_data.append(battery_rating)\n",
    "    temp_data.append(display_rating)\n",
    "    temp_data.append(value_for_money)\n",
    "    temp_data.append(seller_name)\n",
    "    temp_data.append(seller_ratings)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mobiles_data_list(mobile_company_page_link):\n",
    "    \"\"\"Provides Company's Mobiles list\"\"\"\n",
    "    global url\n",
    "    global temp_data\n",
    "    global final_data\n",
    "    \n",
    "    mobile_company_page = requests.get(mobile_company_page_link)\n",
    "    htmCont = mobile_company_page.content\n",
    "    \n",
    "    soup =  BeautifulSoup(htmCont,'html.parser')\n",
    "    mobile_divison = soup.find('div',class_=\"_1YokD2 _3Mn1Gg\")\n",
    "    \n",
    "    mobile_containers = mobile_divison.find_all('div',class_=\"_1AtVbE col-12-12\")\n",
    "    \n",
    "    i=0\n",
    "    for mobile in mobile_containers:\n",
    "        i+=1\n",
    "        if i==25:\n",
    "            break\n",
    "        \n",
    "        try:\n",
    "            title = mobile.find('div',class_=\"_4rR01T\").text\n",
    "            name = title.split('(')[0].strip()\n",
    "            colour = title.split('(')[1].split(',')[0].strip()\n",
    "            rom = title.split('(')[1].split(',')[1].split(')')[0]\n",
    "        except:\n",
    "            name =\"NA\"\n",
    "            colour =\"NA\"\n",
    "            rom = \"NA\"\n",
    "\n",
    "        selling_price = mobile.find('div',class_=\"_30jeq3 _1_WHN1\").text\n",
    "        \n",
    "        temp_data.append(name)\n",
    "        temp_data.append(selling_price)\n",
    "        temp_data.append(colour)\n",
    "        temp_data.append(rom.strip())\n",
    "        \n",
    "        content_list = mobile.find_all('li',class_=\"rgWa7D\")\n",
    "        \n",
    "        add_list_contents(content_list)\n",
    "        \n",
    "        try:\n",
    "            ratings = mobile.find('div',class_=\"_3LWZlK\").text\n",
    "        except:\n",
    "            ratings = \"NA\"\n",
    "        \n",
    "        temp_data.append(ratings)\n",
    "        \n",
    "        detail_link = url + mobile_containers[0].find('a',class_=\"_1fQZEK\")['href']\n",
    "        \n",
    "        get_seller_info(detail_link)\n",
    "        \n",
    "        temp_data.append(detail_link)\n",
    "        \n",
    "\n",
    "        final_data.append(temp_data)\n",
    "\n",
    "        temp_data=[]\n",
    "\n",
    "        if len(final_data)==24:\n",
    "            upload_to_excel(final_data)\n",
    "            final_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mobile_list_page_link(mobile_category_page_link):\n",
    "    \"\"\"Provides mobile list pages link by company to company\"\"\"\n",
    "    \n",
    "    global url\n",
    "    global final_data\n",
    "    \n",
    "    page = requests.get(mobile_category_page_link)\n",
    "    htmCont = page.content\n",
    "    soup =  BeautifulSoup(htmCont,'html.parser')\n",
    "    \n",
    "    mobile_category = soup.find_all('div',class_=\"_3YgSsQ\")\n",
    "\n",
    "    for category in mobile_category:\n",
    "        link = category.find('a',class_=\"h1Fvn6\")['href']\n",
    "        \n",
    "        mobile_company_page_link = url+link\n",
    "        get_mobiles_data_list(mobile_company_page_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_mobile_list_page_link(mobile_category_page_link)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
